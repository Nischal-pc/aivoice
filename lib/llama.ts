import { config } from "./config"

// In-memory store for conversation history (for dummy mode)
const conversationHistory = new Map<string, { role: string; content: string }[]>()

/**
 * Generates a response from Meta's LLAMA 3.0 model (or dummy response in dummy mode)
 * @param userInput The user's speech input
 * @param callSid The Twilio call SID to track conversation history
 * @returns AI-generated response
 */
export async function generateLlamaResponse(userInput: string, callSid: string): Promise<string> {
  try {
    if (config.useDummyData) {
      console.log(`Using dummy LLAMA API endpoint: ${config.urls.llamaApiEndpoint}`)

      // In dummy mode, return predefined responses based on input
      if (userInput.toLowerCase().includes("balance")) {
        return "Your current account balance is $1,250.75. Is there anything else you'd like to know?"
      } else if (userInput.toLowerCase().includes("transaction")) {
        return "Your last transaction was a deposit of $500 on October 15, 2023. Would you like more details about your recent transactions?"
      } else if (userInput.toLowerCase().includes("thank")) {
        return "You're welcome! Is there anything else I can assist you with today?"
      } else {
        return "I'm here to help with your banking needs. You can ask about your account balance, recent transactions, or other banking services."
      }
    }

    // Get or initialize conversation history for this call
    if (!conversationHistory.has(callSid)) {
      conversationHistory.set(callSid, [
        {
          role: "system",
          content: `You are EchoLink, an AI voice assistant powered by Meta's LLAMA 3.0. 
          You are currently on a phone call with a user. 
          Keep your responses concise and conversational, as they will be read aloud.
          Avoid using markdown, links, or special formatting.
          If you don't know something, admit it politely.
          Always maintain a helpful, friendly tone.`,
        },
      ])
    }

    const history = conversationHistory.get(callSid)!

    // Add user input to history
    history.push({
      role: "user",
      content: userInput,
    })

    // In a real implementation, this would call the actual LLAMA API
    // For now, we'll just return a dummy response
    const response =
      "This is a dummy response from LLAMA 3.0. In a real implementation, this would be generated by the AI model."

    // Add assistant response to history
    history.push({
      role: "assistant",
      content: response,
    })

    // Update conversation history
    conversationHistory.set(callSid, history)

    return response
  } catch (error) {
    console.error("Error generating LLAMA response:", error)
    return "I'm sorry, I'm having trouble understanding right now. Could you please try again?"
  }
}

/**
 * Saves the conversation history to a database
 * @param callSid The Twilio call SID
 */
export async function saveConversationHistory(callSid: string): Promise<void> {
  try {
    if (config.useDummyData) {
      console.log(`Mock saving conversation history for call ${callSid}`)
      return
    }

    const history = conversationHistory.get(callSid)
    if (!history) return

    // Here you would save the conversation to your database
    console.log(`Saving conversation history for call ${callSid}`)

    // Clear the in-memory history
    conversationHistory.delete(callSid)
  } catch (error) {
    console.error("Error saving conversation history:", error)
  }
}

/**
 * Gets the conversation history for a call (for UI display)
 * @param callSid The Twilio call SID
 * @returns Conversation history in a format suitable for UI display
 */
export function getConversationForUI(callSid: string): any[] {
  if (config.useDummyData) {
    return config.dummyConversation
  }

  const history = conversationHistory.get(callSid)
  if (!history) return []

  // Transform the history into a format suitable for UI display
  return history
    .filter((msg) => msg.role !== "system")
    .map((msg, index) => ({
      speaker: msg.role === "user" ? "User" : "AI",
      text: msg.content,
      time: `00:${index * 5}`.padStart(5, "0"),
    }))
}

